# SignSense-Bridging-Gaps-in-Communication-through-ASL-Detection
  Innovative project leveraging Random Forest &amp; Logistic Regression for real-time ASL alphabet recognition. Explored LSTMs for complex hand movements. Future vision: Evolving into a user-friendly web app. Open to collaboration and ideas. [My 2nd Year College Project] 

#Abstract
SignSense utilizes Random Forest and Logistic Regression models for ASL alphabet recognition. The project also experimented with LSTMs for handling composite hand movements (Note: LSTM stack is not provided in the repository).

#Implementation
-Data Collection
-Capture diverse images and videos of ASL signers for dataset creation.
-Data Preprocessing
-Resize, normalize, and augment the dataset for effective model training.

#Model Training
-Train Random Forest: train.ipynb
-Real-time Testing
-Use realtimetest_2.0.ipynb for real-time ASL alphabet recognition.

#Usage
-Data Collection
Refer to pnew.ipynb for the data collection process.
-Data Preprocessing
-Explore create_dtset.ipynb for dataset preprocessing.
-Model Training
Train Logistic Regression: train.ipynb

#Deployment
-Host the web application on a server or cloud platform for public access.

#Future Plans
-Evolve the project into a user-friendly web application for broader accessibility.
-Open to collaboration and ideas for further improvement and implementation of LSTMs.

License
This project is licensed under the MIT License.

Contact
For inquiries or collaboration, reach out to me via meghajjadhav17@gmail.com

Feel free to explore and contribute to SignSense!
